{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# -----------------------------------------------------------------------------\n",
    "# import pip\n",
    "# pip.main(['install', 'seaborn']) \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "import platform\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "running_on = 'server' if 'Linux' in platform.system() else 'my_mac'\n",
    "\n",
    "if running_on == 'my_mac':\n",
    "    data_path = '/Users/ranigera/Dropbox/DTI_tests'\n",
    "    preproc_path = '/Users/ranigera/Dropbox/DTI_tests/preproc'\n",
    "    launch_files_path = '/Users/ranigera/Dropbox/DTI_analysis/launch_files'\n",
    "else:\n",
    "    data_path = '/export2/DATA/HIS/HIS_server/BIDS'\n",
    "    preproc_path = '/export2/DATA/HIS/HIS_server/analysis/dwi_data/preproc'\n",
    "    launch_files_path = '/export2/DATA/HIS/HIS_server/codes_dwi/launch_files'\n",
    "\n",
    "expectedVolums = {\n",
    "    'AP': 69,\n",
    "    'PA' : 7,\n",
    "    }\n",
    "expectedB0s_indxs = {\n",
    "    'AP_before': [0, 1, 18, 35, 52],\n",
    "    'PA_before': [0, 2, 3, 4, 5, 6],\n",
    "    'AP_after': [0, 1, 18, 35, 52],\n",
    "    'PA_after': [0, 2, 3, 4, 5, 6]\n",
    "    }\n",
    "\n",
    "n_cores_TOPUP = 2\n",
    "\n",
    "# setting EDDY stuff:\n",
    "EDDY_command = 'eddy_openmp' if running_on == 'server' else 'eddy' # for the boost server\n",
    "EDDY_command = 'eddy_cuda10.2' if running_on == 'server' else 'eddy' # for the cheshire server\n",
    "ssh_command_for_cheshire_server = 'ssh shirangera@cheshire.tau.ac.il' if 'boost' in socket.gethostname() else ''\n",
    "\n",
    "n_expected_EDDY_output_files = 13\n",
    "n_cores_EDDY = 4 # relevant only for running using files (currently disabled as I run it on cheshire's GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "# -----------------------------------------------------------------------------\n",
    "def createSubjectScansBaseNames(subjFolder, data_path):\n",
    "    sub = int(subjFolder.split(\"-\",1)[1])\n",
    "    group = '1day' if sub < 200 else '3day'\n",
    "    last_sess = group[0]\n",
    "    DWI_path_before = os.path.join(data_path, subjFolder, 'ses-1/dwi/')\n",
    "    DWI_path_after = os.path.join(data_path, subjFolder, f'ses-{last_sess}/dwi/')\n",
    "    scansBaseNames = {\n",
    "        'AP_before': f'{os.path.join(DWI_path_before, \"sub-\" + str(sub) + \"_ses-1_acq-ap_run-01_dwi\")}',\n",
    "        'PA_before' : f'{os.path.join(DWI_path_before, \"sub-\" + str(sub) + \"_ses-1_acq-pa_run-01_dwi\")}',\n",
    "        'AP_after' : f'{os.path.join(DWI_path_after, \"sub-\" + str(sub) + \"_ses-\" + last_sess + \"_acq-ap_run-02_dwi\")}',\n",
    "        'PA_after' : f'{os.path.join(DWI_path_after, \"sub-\" + str(sub) + \"_ses-\" + last_sess + \"_acq-pa_run-02_dwi\")}'\n",
    "        }\n",
    "    return scansBaseNames\n",
    "\n",
    "def get_sub_B0_files(subjFolder, scansBaseNames, B0s_indxs):\n",
    "    sub_B0s_files = []\n",
    "    for scan in scansBaseNames.keys():\n",
    "        for B0ind in B0s_indxs[scan]:\n",
    "            B0_file_name = os.path.join(preproc_path, subjFolder, subjFolder + '_' + scan + \"_b0_volInd-\" + str(B0ind) + \".nii.gz\")\n",
    "            sub_B0s_files.append(B0_file_name)\n",
    "    return sub_B0s_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Get sub folders\n"
     ]
    }
   ],
   "source": [
    "# Get folders and remove excluded subjects\n",
    "# -----------------------------------------------------------------------------\n",
    "print('>> Get sub folders')\n",
    "subjFolders = [el for el in os.listdir(data_path) if 'sub' in el]\n",
    "\n",
    "if running_on == 'my_mac':\n",
    "    print('>> Get exclusion list')\n",
    "    with open('/Users/ranigera/Google_Drive_TAU/Experiments/HIS_STUDY/Analysis/codes/paths_and_vars.py') as txtFile:\n",
    "        txt = txtFile.read()\n",
    "    participantsToExclude = [int(el) for el in txt.split('participantsToExclude = [')[1].split(']')[0].replace('\\n','').replace('\\n','').replace(\"'\",\"\").split(',')]\n",
    "\n",
    "    print('>> Remove sub folders of excluded participants in case they are there')\n",
    "    subjFolders = [el for el in subjFolders if int(el.split('-')[1]) not in participantsToExclude]\n",
    "\n",
    "subjFolders.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing scans or wrong phase encoding directions for ALL SUBJECTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Verify that all the scans exist and that the phase encoding directions are as they should.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-101/ses-1/dwi/sub-101_ses-1_acq-pa_run-01_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-101/ses-1/dwi/sub-101_ses-1_acq-pa_run-02_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-110/ses-1/dwi/sub-110_ses-1_acq-pa_run-01_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-110/ses-1/dwi/sub-110_ses-1_acq-pa_run-02_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-204/ses-3/dwi/sub-204_ses-3_acq-pa_run-02_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-207/ses-1/dwi/sub-207_ses-1_acq-pa_run-01_dwi.json is defined as j-.\n",
      " *** There is a problem with the scanning directions: /export2/DATA/HIS/HIS_server/BIDS/sub-209/ses-1/dwi/sub-209_ses-1_acq-pa_run-01_dwi.json is defined as j-.\n",
      " *** Scan not found: /export2/DATA/HIS/HIS_server/BIDS/sub-211/ses-3/dwi/sub-211_ses-3_acq-ap_run-02_dwi.json\n",
      " *** Scan not found: /export2/DATA/HIS/HIS_server/BIDS/sub-211/ses-3/dwi/sub-211_ses-3_acq-pa_run-02_dwi.json\n",
      " *** Scan not found: /export2/DATA/HIS/HIS_server/BIDS/sub-255/ses-1/dwi/sub-255_ses-1_acq-pa_run-01_dwi.json\n",
      " *** Scan not found: /export2/DATA/HIS/HIS_server/BIDS/sub-259/ses-3/dwi/sub-259_ses-3_acq-ap_run-02_dwi.json\n",
      " *** Scan not found: /export2/DATA/HIS/HIS_server/BIDS/sub-259/ses-3/dwi/sub-259_ses-3_acq-pa_run-02_dwi.json\n"
     ]
    }
   ],
   "source": [
    "print ('>> Verify that all the scans exist and that the phase encoding directions are as they should.')\n",
    "subjectsWithAProblem = []\n",
    "for subjFolder in subjFolders:\n",
    "    sub = int(subjFolder.split(\"-\",1)[1])\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "    for scan in scansBaseNames.keys():\n",
    "        # print(scansBaseNames[scan] + '.json')\n",
    "        # print(scanData['PhaseEncodingDirection'])\n",
    "        if not os.path.exists(scansBaseNames[scan] + '.json'):\n",
    "            subjectsWithAProblem.append(sub)\n",
    "            print(' *** Scan not found: ' + scansBaseNames[scan] + '.json')\n",
    "            continue\n",
    "        with open(scansBaseNames[scan] + '.json') as json_file:        \n",
    "            scanData = json.load(json_file)\n",
    "            if ('acq-ap_' in scansBaseNames[scan] and scanData['PhaseEncodingDirection'] != 'j-') or \\\n",
    "                ('acq-pa_' in scansBaseNames[scan] and scanData['PhaseEncodingDirection'] != 'j'):\n",
    "                subjectsWithAProblem.append(sub)\n",
    "                print(' *** There is a problem with the scanning directions: ' + scansBaseNames[scan] + '.json is defined as ' + scanData['PhaseEncodingDirection'] + '.')\n",
    "                continue\n",
    "\n",
    "subjectsWithAProblem = list(set(subjectsWithAProblem))\n",
    "subjectsWithAProblem.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Remove subjects with a problem\n"
     ]
    }
   ],
   "source": [
    "# Remove subjects with a problem\n",
    "# -----------------------------------------------------------------------------\n",
    "print('>> Remove subjects with a problem')\n",
    "subjFolders =[el for el in subjFolders if int(el.split('-')[1]) not in subjectsWithAProblem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get b0 volume indices and perform bval & bvec QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n",
      "> Verify that data points in the bval files is as expected.\n",
      "> Verify that data points in the bvec files is as expected.\n",
      "> Extract B0s:\n",
      "> Verify that b0 quantity and indices are as expected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subjFolder in subjFolders:\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "    print('> Verify that data points in the bval files is as expected.')\n",
    "    if pd.read_csv(scansBaseNames['AP_before'] + '.bval', header=None, sep=' ').T.shape[0] != expectedVolums['AP'] or \\\n",
    "        pd.read_csv(scansBaseNames['PA_before'] + '.bval', header=None, sep=' ').T.shape[0] != expectedVolums['PA'] or \\\n",
    "        pd.read_csv(scansBaseNames['AP_after'] + '.bval', header=None, sep=' ').T.shape[0] != expectedVolums['AP'] or \\\n",
    "        pd.read_csv(scansBaseNames['PA_after'] + '.bval', header=None, sep=' ').T.shape[0] != expectedVolums['PA']:\n",
    "            print(f' *** The number of data points in the bval for one of the scans for subjetc {sub} is not as expected.')\n",
    "            raise Exception(f'The number of data points in the bval for one of the scans for subjetc {sub} is not as expected.')\n",
    "\n",
    "    print('> Verify that data points in the bvec files is as expected.')\n",
    "    if pd.read_csv(scansBaseNames['AP_before'] + '.bvec', header=None, sep=' ').T.shape[0] != expectedVolums['AP'] or \\\n",
    "        pd.read_csv(scansBaseNames['PA_before'] + '.bvec', header=None, sep=' ').T.shape[0] != expectedVolums['PA'] or \\\n",
    "        pd.read_csv(scansBaseNames['AP_after'] + '.bvec', header=None, sep=' ').T.shape[0] != expectedVolums['AP'] or \\\n",
    "        pd.read_csv(scansBaseNames['PA_after'] + '.bvec', header=None, sep=' ').T.shape[0] != expectedVolums['PA']:\n",
    "            print(f' *** The number of data points in the bvec for one of the scans for subjetc {sub} is not as expected.')\n",
    "            raise ValueError(f'The number of data points in the bvec for one of the scans for subjetc ' + str(sub) + ' is not as expected.')\n",
    "\n",
    "    print('> Extract B0s:')\n",
    "    B0s_indxs = {}\n",
    "    for scan in scansBaseNames.keys():\n",
    "        B0s=pd.read_csv(scansBaseNames[scan] + '.bval', header=None, sep=' ').T\n",
    "        B0s.columns = ['bval']\n",
    "        B0s_indxs[scan] = list(B0s[B0s.bval < 20].index)\n",
    "\n",
    "    print('> Verify that b0 quantity and indices are as expected.')\n",
    "    if B0s_indxs != expectedB0s_indxs:\n",
    "        print(f' *** The indices of the b0s for one of the scans for subjetc {sub} are not as expected.')\n",
    "        raise ValueError(f'The indices of the b0s for one of the scans for subjetc ' + str(sub) + ' are not as expected.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pre-processing folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create preprocessing folders\n"
     ]
    }
   ],
   "source": [
    "print('> Create preprocessing folders')\n",
    "for subjFolder in subjFolders:\n",
    "    try:\n",
    "        os.makedirs(os.path.join(preproc_path, subjFolder), exist_ok=False)\n",
    "        print('>> Created folder: ' + os.path.join(preproc_path, subjFolder))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) TOPUP\n",
    "* A tool for estimating and correcting susceptibility induced distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract B0 volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Extract B0s (using the fslroi):\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Extract B0s (using the fslroi):')\n",
    "for subjFolder in subjFolders:\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "    for scan in scansBaseNames.keys():\n",
    "        for B0ind in B0s_indxs[scan]:\n",
    "            B0_file_name = os.path.join(preproc_path, subjFolder, subjFolder + '_' + scan + \"_b0_volInd-\" + str(B0ind) + \".nii.gz\")\n",
    "            if not os.path.isfile(f\"{B0_file_name}\"):\n",
    "                print(f'>> runs: fslroi {scansBaseNames[scan]}.nii.gz {B0_file_name} {B0ind} 1')\n",
    "                os.system(f'fslroi {scansBaseNames[scan]}.nii.gz {B0_file_name} {B0ind} 1')\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge B0 volumes for TOPUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merge B0s for each session (using the fslmerge):\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Merge B0s for each session (using the fslmerge):')\n",
    "#print([scan for scan in sub_B0s_files if 'AP_before' in scan])\n",
    "#print([scan for scan in sub_B0s_files if 'PA_before' in scan])\n",
    "for subjFolder in subjFolders:\n",
    "    # get the sub_B0s_files for the current subject:\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "    sub_B0s_files = get_sub_B0_files(subjFolder, scansBaseNames, B0s_indxs)\n",
    "    # merge the B0s for the current subject for each time (before/after):\n",
    "    for time in ['before', 'after']:\n",
    "        output_base_name = f'{os.path.join(preproc_path, subjFolder,subjFolder)}_AP_PA_{time}_b0s'\n",
    "        if not os.path.isfile(f\"{output_base_name}.nii.gz\"):\n",
    "            print(f'>> runs: fslmerge -t {output_base_name}' + ' ' + ' '.join([scan for scan in sub_B0s_files if f'AP_{time}' in scan]) + ' ' + ' '.join([scan for scan in sub_B0s_files if f'PA_{time}' in scan]))\n",
    "            os.system(f'fslmerge -t {output_base_name}' + ' ' + ' '.join([scan for scan in sub_B0s_files if f'AP_{time}' in scan]) + ' ' + ' '.join([scan for scan in sub_B0s_files if f'PA_{time}' in scan]))\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the acqparams.txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create the acqparams.txt files (one per session [before and after])\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Create the acqparams.txt files (one per session [''before'' and ''after''])')\n",
    "\n",
    "for subjFolder in subjFolders:\n",
    "    # get the sub_B0s_files for the current subject:\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "    sub_B0s_files = get_sub_B0_files(subjFolder, scansBaseNames, B0s_indxs)\n",
    "\n",
    "    # first get the totalReadoutTime from the json files\n",
    "    total_readout_time = {}\n",
    "    for scanBaseName in scansBaseNames.keys():\n",
    "        with open(scansBaseNames[scanBaseName] + '.json') as json_file:        \n",
    "            scanData = json.load(json_file)\n",
    "            total_readout_time[scanBaseName] = scanData['TotalReadoutTime']\n",
    "\n",
    "    for time in ['before', 'after']:\n",
    "        acqPars=[f'0 -1 0 {total_readout_time[f\"AP_{time}\"]}' for scan in sub_B0s_files if f'AP_{time}' in scan] + [f'0 1 0 {total_readout_time[f\"PA_{time}\"]}' for scan in sub_B0s_files if f'PA_{time}' in scan]\n",
    "        # write a list of strings to a file (one string per line):\n",
    "        with open(os.path.join(preproc_path, subjFolder, subjFolder + f'_{time}_acqparams.txt'), 'w') as f:\n",
    "            for item in acqPars:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TOPUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create TOPUP launch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create the TOPUP launch files (one per subject [before and after] together)\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Create the TOPUP launch files (one per subject [''before'' and ''after''] together)')\n",
    "for subjFolder in subjFolders:\n",
    "\n",
    "    launch_file = os.path.join(launch_files_path, 'TOPUP_' + subjFolder + '_launch.txt')\n",
    "    \n",
    "    if not os.path.isfile(launch_file):\n",
    "        with open(launch_file, 'w') as f:\n",
    "            for time in ['before', 'after']:\n",
    "                    print(f\">> This command was written to {launch_file}:\\ntopup --imain={os.path.join(preproc_path, subjFolder,subjFolder)}_AP_PA_{time}_b0s \\\\\\n\\\n",
    "                            --datain={os.path.join(preproc_path, subjFolder, subjFolder + f'_{time}_acqparams.txt')} \\\\\\n\\\n",
    "                            --config=b02b0.cnf \\\\\\n\\\n",
    "                            --out={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s \\\\\\n\\\n",
    "                            --iout={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout \\\\\\n\\\n",
    "                            --fout={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_fout \\n\\\n",
    "                        \")\n",
    "                    f.write(f\"topup --imain={os.path.join(preproc_path, subjFolder,subjFolder)}_AP_PA_{time}_b0s --datain={os.path.join(preproc_path, subjFolder, subjFolder + f'_{time}_acqparams.txt')} --config=b02b0.cnf --out={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s --iout={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout --fout={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_fout\\n\")\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TOPUP launch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Run the TOPUP launch files (one per subject [before and after] together)\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Run the TOPUP launch files (one per subject [''before'' and ''after''] together)')\n",
    "\n",
    "for subjFolder in subjFolders:\n",
    "\n",
    "    launch_file = os.path.join(launch_files_path, 'TOPUP_' + subjFolder + '_launch.txt')\n",
    "\n",
    "    # check if all expected output files exist:\n",
    "    expected_TOPUP_out_files_exist = []\n",
    "    for time in ['before', 'after']:\n",
    "        expected_TOPUP_out_files_exist += [os.path.isfile(f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_fieldcoef.nii.gz\"),\n",
    "                                        os.path.isfile(f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_fout.nii.gz\"),\n",
    "                                        os.path.isfile(f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout.nii.gz\"),\n",
    "                                        os.path.isfile(f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_movpar.txt\")]\n",
    "\n",
    "    # Run the launch file if not all output files present:\n",
    "    if not all(expected_TOPUP_out_files_exist):\n",
    "                print(f\">> Running: launch -s {launch_file} -j schonberglab -p {n_cores_TOPUP} -r inf\")\n",
    "                #os.system(f\">> Running: launch -s {launch_file} -j schonberglab -p {n_cores_TOPUP} -r inf\")         \n",
    "                \n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) EDDY\n",
    "* A tool for correcting Eddy currents (and motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average TOPUP corrected (unwarped) B0 volums (the .iout file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Average TOPUP corrected (unwarped) B0 volums (the .iout file). - runs seperately for each time [''before'' and ''after'']\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Average TOPUP corrected (unwarped) B0 volums (the .iout file). - runs seperately for each time [''before'' and ''after'']\")\n",
    "for subjFolder in subjFolders:\n",
    "      for time in ['before', 'after']:\n",
    "            output_file_name = f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg.nii.gz\"\n",
    "            if not os.path.isfile(f\"{output_file_name}\"):\n",
    "                  print(f\">> runs: fslmaths {os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout -Tmean {output_file_name}\")\n",
    "                  os.system(f\"fslmaths {os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout -Tmean {output_file_name}\")\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run BET on the averaged B0s volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Extarct the brain form the averaged B0s volume - runs seperately for each time [''before'' and ''after'']\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Extarct the brain form the averaged B0s volume - runs seperately for each time [''before'' and ''after'']\")\n",
    "for subjFolder in subjFolders:\n",
    "      for time in ['before', 'after']:\n",
    "            output_base_name = f\"{os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg_brain\"\n",
    "            if not os.path.isfile(f\"{output_base_name}.nii.gz\") or not os.path.isfile(f\"{output_base_name}_mask.nii.gz\"):\n",
    "                  print(f\">> runs: bet {os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg {output_base_name} -m -f 0.2\")\n",
    "                  os.system(f\"bet {os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg {output_base_name} -m -f 0.2\")\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index.txt file\n",
    "This file maps the volumes in the main DTI data to the relevant line in the acqparams.txt and in the movpar.txt (assessed movement parameters from TOPUP) files\n",
    "* details in: https://www.youtube.com/watch?v=1T1cRnX7MpA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> create an index.txt file for each subject for each time [before and after] for the EDDY\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print(f\">> create an index.txt file for each subject for each time [before and after] for the EDDY\")\n",
    "for subjFolder in subjFolders:\n",
    "    for time in ['before', 'after']:\n",
    "        ind_to_write = 1\n",
    "        with open(os.path.join(preproc_path, subjFolder, f'{time}_index.txt'), 'w') as f:\n",
    "            for i in range(expectedVolums['AP']):   \n",
    "                if i > 0 and i in expectedB0s_indxs[f'AP_{time}']:\n",
    "                    ind_to_write += 1\n",
    "                f.write(\"%s\\n\" %ind_to_write)\n",
    "print('>> COMPLETED.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run EDDY\n",
    "* Correct for eddy currents and subject movement (and taking to account the suceptibility field calculated by TOPUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Run EDDY using cheshire server GPU (one per subject per time [before and after])\n",
      ">> COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "print('> Run EDDY using cheshire server GPU (one per subject per time [''before'' and ''after''])')\n",
    "# files_to_run_each_time = 200\n",
    "# counter=1\n",
    "for subjFolder in subjFolders:\n",
    "    # if int(subjFolder.split('-')[1])<265:\n",
    "    #     continue\n",
    "\n",
    "    # # Stop executing more:\n",
    "    # if counter > files_to_run_each_time:\n",
    "    #     break\n",
    "\n",
    "    scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "\n",
    "    # check if all expected output files exist:\n",
    "    for time in ['before', 'after']:\n",
    "        \n",
    "        eddy_output_files = glob.glob(os.path.join(preproc_path, subjFolder, f'eddy_unwarped_images_{subjFolder}_{time}*')) # get files in a directory\n",
    "        expected_EDDY_out_files_exist = len(list(set(eddy_output_files))) == n_expected_EDDY_output_files # check that the number of unique EDDY files is as expected\n",
    "\n",
    "        # Run the launch file if not all output files present:\n",
    "        if not expected_EDDY_out_files_exist:\n",
    "            eddy_command_to_run = f\"{ssh_command_for_cheshire_server} {EDDY_command} --imain={scansBaseNames[f'AP_{time}']}.nii.gz \\\\\\n\\\n",
    "                --mask={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg_brain_mask \\\\\\n\\\n",
    "                --index={os.path.join(preproc_path, subjFolder, time + '_index.txt')}\\\\\\n\\\n",
    "                --acqp={os.path.join(preproc_path, subjFolder, subjFolder + '_' + time + '_acqparams.txt')} \\\\\\n\\\n",
    "                --bvecs={scansBaseNames[f'AP_{time}']}.bvec \\\\\\n\\\n",
    "                --bvals={scansBaseNames[f'AP_{time}']}.bval \\\\\\n\\\n",
    "                --topup={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s \\\\\\n\\\n",
    "                --out={os.path.join(preproc_path, subjFolder,'eddy_unwarped_images_' + subjFolder)}_{time} \\\\\\n\\\n",
    "                --verbose\\\n",
    "            \"\n",
    "            print(f'\">> Running this command on cheshire:\\n{eddy_command_to_run}\\n')\n",
    "            os.system(eddy_command_to_run)\n",
    "            # counter+=1\n",
    "\n",
    "print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create EDDY launch files [Currently not in use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('> Create the EDDY launch files (one per subject [''before'' and ''after''] together)')\n",
    "# for subjFolder in subjFolders:\n",
    "\n",
    "#     scansBaseNames = createSubjectScansBaseNames(subjFolder, data_path)\n",
    "#     launch_file = os.path.join(launch_files_path, 'EDDY_' + subjFolder + '_launch.txt')\n",
    "\n",
    "#     if not os.path.isfile(launch_file):\n",
    "#         with open(launch_file, 'w') as f:\n",
    "#             for time in ['before', 'after']:\n",
    "#                 print(f\">> This command was written to {launch_file}:\\n{EDDY_command} --imain={scansBaseNames[f'AP_{time}']}.nii.gz \\\\\\n\\\n",
    "#                     --mask={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg_brain_mask \\\\\\n\\\n",
    "#                     --index={os.path.join(preproc_path, subjFolder, time + '_index.txt')}\\\\\\n\\\n",
    "#                     --acqp={os.path.join(preproc_path, subjFolder, subjFolder + '_' + time + '_acqparams.txt')} \\\\\\n\\\n",
    "#                     --bvecs={scansBaseNames[f'AP_{time}']}.bvec \\\\\\n\\\n",
    "#                     --bvals={scansBaseNames[f'AP_{time}']}.bval \\\\\\n\\\n",
    "#                     --topup={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s \\\\\\n\\\n",
    "#                     --out={os.path.join(preproc_path, subjFolder,'eddy_unwarped_images_' + subjFolder)}_{time} \\\\\\n\\\n",
    "#                     --verbose \\n\\\n",
    "#                 \")\n",
    "#                 #f.write(f\"{EDDY_command} --imain={scansBaseNames[f'AP_{time}']}.nii.gz --mask={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s_iout_avg_brain_mask --index={os.path.join(preproc_path, subjFolder, time + '_index.txt')} --acqp={os.path.join(preproc_path, subjFolder, subjFolder + '_' + time + '_acqparams.txt')} --bvecs={scansBaseNames[f'AP_{time}']}.bvec --bvals={scansBaseNames[f'AP_{time}']}.bval --topup={os.path.join(preproc_path, subjFolder,'topup_' + subjFolder)}_AP_PA_{time}_b0s --out={os.path.join(preproc_path, subjFolder,'eddy_unwarped_images_' + subjFolder)}_{time} --verbose\\n\")\n",
    "# print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run EDDY launch files  [Currently not in use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('> Run the EDDY launch files (one per subject [''before'' and ''after''] together)')\n",
    "# for subjFolder in subjFolders:\n",
    "\n",
    "#     launch_file = os.path.join(launch_files_path, 'EDDY_' + subjFolder + '_launch.txt')\n",
    "\n",
    "#     # check if all expected output files exist:\n",
    "#     expected_EDDY_out_files_exist = []\n",
    "#     for time in ['before', 'after']:\n",
    "#         eddy_output_files = glob.glob(os.path.join(preproc_path, subjFolder, f'eddy_unwarped_images_{subjFolder}_{time}*')) # get files in a directory\n",
    "#         expected_EDDY_out_files_exist.append(len(list(set(eddy_output_files))) == n_expected_EDDY_output_files) # check that the number of unique EDDY files is as expected\n",
    "\n",
    "#     # Run the launch file if not all output files present:\n",
    "#     if not all(expected_EDDY_out_files_exist):\n",
    "#                 print(f\">> Running: launch -s {launch_file} -j schonberglab -p {n_cores_EDDY} -r inf\")\n",
    "#                 #os.system(f\">> Running: launch -s {launch_file} -j schonberglab -p {n_cores_EDDY} -r inf\")\n",
    "# print(f\">> COMPLETED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run EDDY QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-120'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/ranigera/Dropbox/DTI_tests/preproc/sub-120/before_index.txt'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{os.path.join(preproc_path, subjFolder, f'{time}_index.txt')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weew\n",
      "werewr\n"
     ]
    }
   ],
   "source": [
    "print('weew\\nwerewr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in ['before', 'after']:\n",
    "    os.system(f\"eddy_quad {os.path.join(preproc_path, subjFolder, f'eddy_unwarped_images_{subjFolder}_{time}')} \\\n",
    "    -idx {os.path.join(preproc_path, subjFolder, f'{time}_index.txt')} \\\n",
    "    -par {os.path.join(preproc_path, subjFolder, subjFolder  + f'_{time}_acqparams.txt')} \\\n",
    "    -m   {os.path.join(preproc_path, subjFolder, f'topup_{subjFolder}_AP_PA_{time}_b0s_iout_avg_brain_mask.nii.gz')} \\\n",
    "    -b   {scansBaseNames[f'AP_{time}'] + '.bval'}\")\n",
    "\n",
    "#f{os.path.join(preproc_path, subjFolder, f'eddy_unwarped_images_{subjFolder}_{time}')} -idx {time}_index.txt -par sub-120_before_acqparams.txt -m topup_sub-120_AP_PA_before_b0s_iout_avg_brain_mask.nii.gz -b /Users/ranigera/Dropbox/DTI_tests/sub-120/ses-1/dwi/sub-120_ses-1_acq-ap_run-01_dwi.bval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ranigera/Dropbox/DTI_tests/sub-120/ses-1/dwi/sub-120_ses-1_acq-ap_run-01_dwi.bval'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scansBaseNames[f'AP_{time}'] + '.bval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ranigera/Dropbox/DTI_tests/sub-120/ses-1/dwi/sub-120_ses-1_acq-ap_run-01_dwi'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scansBaseNames[f'AP_{time}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAYGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sched, time\n",
    "s = sched.scheduler(time.time, time.sleep)\n",
    "def do_something(sc): \n",
    "    print(\"Doing stuff...\")\n",
    "    # do your stuff\n",
    "    s.enter(3, 1, do_something, (sc,))\n",
    "\n",
    "s.enter(3, 1, do_something, (s,))\n",
    "s.run()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7504252075d046cca664b6be5d41f96883e23643544d29c440209b91eeb6bd3e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
